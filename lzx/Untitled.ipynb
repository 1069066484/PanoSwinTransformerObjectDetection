{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Anaconda3\\envs\\openmmlab\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cairosvg import error\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from coor_transition import *\n",
    "\n",
    "\n",
    "def preprocess(shape, patch_num_y, patch_size=None, ratio_v=(0.0, 1.0)):\n",
    "    pi = math.pi\n",
    "    X_LEN = shape[1]\n",
    "    Y_LEN = shape[0]\n",
    "    # print(patch_num_y, patch_size, shape);exit() # 20 100 (500, 1000, 3)\n",
    "    # x: [0, X_LEN], u: [0,2pi]\n",
    "    # y: [0, Y_LEN], u: [-0.5pi,0.5pi]\n",
    "    if patch_size is not None:\n",
    "        gap_uv = patch_size / Y_LEN * pi * (ratio_v[1] - ratio_v[0])\n",
    "    else:\n",
    "        gap_uv = pi / patch_num_y\n",
    "    gap_xy = patch_size\n",
    "\n",
    "    U_LEN = shape[1] / gap_xy * gap_uv\n",
    "    V_LEN = pi * (ratio_v[1] - ratio_v[0])\n",
    "\n",
    "    us = [gap_uv * i for i in range( round(U_LEN / gap_uv) )]\n",
    "    vs = [gap_uv * i + (ratio_v[0] - 0.5) * pi for i in range( round(V_LEN / gap_uv) )]\n",
    "    # print(X_LEN, Y_LEN, U_LEN, V_LEN, pi, gap_uv, gap_xy, us, vs);exit() # 10 5\n",
    "    Y_LEN0 = round(Y_LEN / (ratio_v[1] - ratio_v[0]) * ratio_v[0])\n",
    "    Y_LEN1 = round(Y_LEN / (ratio_v[1] - ratio_v[0]) * 1)\n",
    "    return X_LEN, Y_LEN, U_LEN, V_LEN, pi, gap_uv, gap_xy, us, vs, Y_LEN0, Y_LEN1\n",
    "\n",
    "\n",
    "def pose_init(poses):\n",
    "    for p in poses:\n",
    "        assert p in {\"center\", \"center2\", \"left\", \"right\"}\n",
    "    poses = set(poses)\n",
    "    assert ('center2' in poses and len(poses) == 1) or 'center2' not in poses\n",
    "    if poses is None:\n",
    "        poses = ['center']\n",
    "    return poses\n",
    "\n",
    "\n",
    "def correct(tc_im, patch_num_y=20, patch_size=None, poses=None, ratio_v=(0.0, 1.0)):\n",
    "    poses = pose_init(poses)\n",
    "\n",
    "    X_LEN, Y_LEN, U_LEN, V_LEN, pi, gap_uv, gap_xy, us, vs, Y_LEN0, Y_LEN1 = preprocess(\n",
    "        tc_im.shape[1:], patch_num_y, patch_size, ratio_v=ratio_v)\n",
    "    # X_LEN, Y_LEN, pi, gap, gap2, us, vs = preprocess(tc_im.shape[1:], patch_num_y, patch_size)\n",
    "    # print(X_LEN, Y_LEN, U_LEN, V_LEN, pi, gap_uv, gap_xy, us, vs);exit()\n",
    "    if 'center2' in poses:\n",
    "        tc_im = tc_im.roll(round(gap_xy * 0.5), 2)\n",
    "\n",
    "    transed = dict((k, []) for k in poses)\n",
    "    # print(list(transed.keys())); exit()\n",
    "    x2 = 0\n",
    "\n",
    "    for ui, u in enumerate(us):\n",
    "        x = x2\n",
    "        x2 = round((u + gap_uv) / U_LEN * X_LEN)\n",
    "\n",
    "        if ui == len(us) - 1:\n",
    "            x2 = X_LEN # min(round(x2 * 1.1), X_LEN)\n",
    "        for k in transed:\n",
    "            transed[k].append([])\n",
    "\n",
    "        y2 = Y_LEN0\n",
    "        for vi, v in enumerate(vs):\n",
    "            # y = round((v + 0.5 * pi)/ V_LEN  * Y_LEN)\n",
    "            y = y2 # round(Y_LEN / (ratio_v[1] - ratio_v[0]) * ratio_v[0])\n",
    "\n",
    "            y2 = round(y + gap_xy)\n",
    "            if vi == len(us) - 1:\n",
    "                y2 = Y_LEN + Y_LEN0 # min(round(y2 * 1.1), Y_LEN)\n",
    "\n",
    "            curr_ori = tc_im[:, y-Y_LEN0:y2-Y_LEN0, x:x2]\n",
    "\n",
    "            curr_trans = dict((k, torch.zeros_like(curr_ori)) for k in transed)\n",
    "\n",
    "            for it in range(y, y2):\n",
    "                # ? / it = 1 / Y_LEN1\n",
    "                v_it_coord = (it / Y_LEN1 - 0.5) * pi\n",
    "                x_len_it = round(math.cos(v_it_coord) * curr_ori.shape[1])\n",
    "                if x_len_it:\n",
    "                    it -= y\n",
    "                    # print(y, y2, curr_ori.shape, it, x_len_it)\n",
    "                    # torch.Size([3, 44, 50]) 44 42\n",
    "                    # continue\n",
    "                    interpolated = F.interpolate(\n",
    "                            curr_ori[None, :, it:it + 1, :], size=(1, x_len_it))[0]\n",
    "                    if 'center' in curr_trans:\n",
    "                        start = max(round((gap_xy - x_len_it)/2), 0)\n",
    "                        curr_trans['center'][:,it:it+1, start:start+x_len_it] = \\\n",
    "                            interpolated[...,:min(start+x_len_it, curr_trans['center'].shape[-1]) - start]\n",
    "                    if 'center2' in curr_trans:\n",
    "                        start = max(round((gap_xy - x_len_it)/2), 0)\n",
    "                        curr_trans['center2'][:,it:it+1,start:start+x_len_it] =\\\n",
    "                            interpolated[...,:min(start+x_len_it, curr_trans['center2'].shape[-1]) - start]\n",
    "                    if 'left' in curr_trans:\n",
    "                        curr_trans['left'][:,it:it+1,0:x_len_it] = interpolated[...,:min(x_len_it,curr_trans['left'].shape[-1])]\n",
    "                    if 'right' in curr_trans:\n",
    "                        curr_trans['right'][:,it:it+1,-x_len_it:] = interpolated[...,min(x_len_it,-curr_trans['right'].shape[-1]):]\n",
    "            for k in transed:\n",
    "                transed[k][-1].append(curr_trans[k])\n",
    "        # continue\n",
    "        for k in transed:\n",
    "            transed[k][-1] = torch.cat(transed[k][-1], 1)\n",
    "    for k in transed:\n",
    "        transed[k] = torch.cat(transed[k], 2)\n",
    "    if 'center2' in poses:\n",
    "        transed['center2'] = transed['center2'].roll(-round(gap_xy * 0.5), 2)\n",
    "    return transed\n",
    "\n",
    "\n",
    "def basketball_uvmap_foreground(shape, patch_num_y=20, patch_size=None):\n",
    "    # torch.Size([960, 1920])\n",
    "    poses = ['center', 'center2', 'left', 'right']\n",
    "    us = torch.arange(shape[1]) / shape[-1] * math.pi * 2\n",
    "    vs = torch.arange(shape[0]) / shape[-1] * math.pi - math.pi * 0.5\n",
    "    foreground = torch.ones(shape[:2])\n",
    "    uvmap = torch.stack([\n",
    "        us[None].repeat([shape[0], 1]),\n",
    "        vs[:,None].repeat([1, shape[1]]),\n",
    "        foreground\n",
    "    ])\n",
    "    ret = basketball_transition(uvmap, patch_num_y, patch_size, poses)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def basketball_transition(im, patch_num_y=20, patch_size=None, poses=None, ratio_v=(0.0, 1.0)):\n",
    "    # print(\"basketball_transition\", im.shape, patch_num_y,patch_size,  poses, ratio_v)\n",
    "    if isinstance(im, np.ndarray):\n",
    "        tc_im = torch.from_numpy(im.copy()).float()\n",
    "    else:\n",
    "        tc_im = im\n",
    "\n",
    "    if im.shape[-1] == 3:\n",
    "        # 224, 224, 3\n",
    "        tc_im = tc_im.permute(2,0,1)\n",
    "\n",
    "    if poses is None:\n",
    "        poses = ['center']\n",
    "    transed = correct(tc_im, patch_num_y, patch_size, [p for p in poses if p != 'center2'], ratio_v=ratio_v)\n",
    "    if 'center2' in poses:\n",
    "        transed['center2'] = correct(tc_im, patch_num_y, patch_size, ['center2'], ratio_v=ratio_v)['center2']\n",
    "\n",
    "    for k in transed:\n",
    "        if im.shape[-1] == 3:\n",
    "            # 3, 224, 224\n",
    "            transed[k] = transed[k].permute(1,2,0)\n",
    "        if isinstance(im, np.ndarray):\n",
    "            transed[k] = transed[k].numpy().astype(im.dtype)\n",
    "    return transed\n",
    "\n",
    "\n",
    "def basketball_transition_xy(shape, xys, patch_num_y=20, patch_size=None, poses=None):\n",
    "    # xys: [n, 2]\n",
    "    poses = pose_init(poses)\n",
    "    # y does not change\n",
    "    X_LEN, Y_LEN, U_LEN, V_LEN, pi, gap_uv, gap_xy, us, vs = preprocess(shape, patch_num_y, patch_size)\n",
    "    # X_LEN, Y_LEN, pi, gap_uv, gap_xy, us, vs = preprocess(shape, patch_num_y, patch_size)\n",
    "    if 'center2' in poses:\n",
    "        xys[:, 0] = (xys[:, 0] + gap_xy // 2) % X_LEN\n",
    "    transed = {}\n",
    "    us.append(pi * 2)\n",
    "    center_lines = np.array([(us[i] + us[i + 1]) * 0.5 for i in range(len(us) - 1)]) * X_LEN / 2 / pi\n",
    "    interval_index = np.argmin(np.abs(xys[:,0:1] - center_lines[None, :]), -1)\n",
    "    if 'center' in poses:\n",
    "        transed['center'] = center_lines[interval_index]\n",
    "    if 'center2' in poses:\n",
    "        transed['center2'] = center_lines[interval_index]\n",
    "    if 'left' in poses:\n",
    "        transed['left'] = np.array(us)[interval_index] * X_LEN / 2 / pi\n",
    "    if 'right' in poses:\n",
    "        transed['right'] = np.array(us)[1:][interval_index] * X_LEN / 2 / pi\n",
    "    for k in transed:\n",
    "        x_bias = xys[:, 0] - transed[k]\n",
    "        x_bias = x_bias * np.cos((xys[:,1] / Y_LEN - 0.5) * pi)\n",
    "        xys2 = xys.copy()\n",
    "        xys2[:,0] = (np.round(x_bias).astype(np.int) + transed[k] + xys[:,0]) * 0.5\n",
    "        transed[k] = xys2\n",
    "    if 'center2' in transed:\n",
    "        transed['center2'][:, 0] = (xys[:, 0] - gap_xy // 2) % X_LEN\n",
    "    return transed\n",
    "\n",
    "\n",
    "def basketball_transition_bb(shape, tlwh, patch_num_y=20, patch_size=None, poses=None):\n",
    "    xyxy = tlwh2xyxy(tlwh)\n",
    "    if poses is None:\n",
    "        poses = ['center']\n",
    "    transed_xyxy = basketball_transition_xy(shape, xyxy.reshape([-1, 2]),\n",
    "                                            patch_num_y=patch_num_y, patch_size=patch_size,\n",
    "                                            poses=[p for p in poses if p != 'center2'])\n",
    "    if 'center2' in poses:\n",
    "        transed_xyxy['center2'] = basketball_transition_xy(\n",
    "            shape, xyxy.reshape([-1, 2]), patch_num_y=patch_num_y,\n",
    "            poses=['center2'], patch_size=patch_size)['center2']\n",
    "    for k in transed_xyxy:\n",
    "        transed_xyxy[k] = xyxy2tlwh(transed_xyxy[k].reshape(xyxy.shape))\n",
    "    return transed_xyxy\n",
    "\n",
    "\n",
    "def _test_backup():\n",
    "    img_path = r\"E:\\ori_disks\\D\\fduStudy\\labZXD\\repos\\datasets\\hw0805\\data_scaled\\images\\train\\23010301000156__南岗区赣水路德霖高尔夫__机房__全景照片_1625654534870__VID_20210612_090058_00_026_000001.jpg\"\n",
    "    # img_path = r\"E:\\ori_disks\\D\\fduStudy\\labZXD\\repos\\datasets\\Omnidirectional Street-view Dataset\\equirectangular\\JPEGImages\\000002.jpg\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    img = cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), -1)\n",
    "    img = cv2.resize(img, (1334, 667))\n",
    "\n",
    "    # print(img.shape, '222222222222222222222222222222222222222')\n",
    "    # print(img.shape)  # (960, 1920, 3)\n",
    "    # tc_im = transform(img)\n",
    "    # print(tc_im.shape)  # torch.Size([3, 960, 1920])\n",
    "\n",
    "    patch_num_y = 8\n",
    "    transed = basketball_transition(img, patch_num_y, ['center', 'center2', 'left', 'right'])\n",
    "    print([transed[t].shape for t in transed], img.shape)\n",
    "    sz = (400, 200)\n",
    "    print(len(transed))\n",
    "    # sz = (600,300)\n",
    "    for k in transed:\n",
    "        cv_show1(transed[k][..., :3], w=False, name=k, sz=sz)\n",
    "    cv_show1(img, w=True, sz=sz)\n",
    "\n",
    "\n",
    "def rec_img(img, xyxy, txts=None, color=None):\n",
    "    # print(img.shape, img.dtype, np.max(img), np.min(img))\n",
    "    # img = img.astype(np.uint)\n",
    "    for i,  xyxy_i in enumerate(xyxy.astype(np.int)):\n",
    "        clr = (0,255,0) if color is None else \\\n",
    "                            (int(color[i][0]), int(color[i][1]), int(color[i][2]),)\n",
    "        img = cv2.rectangle(img, (xyxy_i[0], xyxy_i[1]), (xyxy_i[0] + xyxy_i[2], xyxy_i[1] + xyxy_i[3]),\n",
    "                            color=clr, thickness=max(img.shape[0] // 500, 1))\n",
    "        if txts is not None:\n",
    "            txt = txts[i]\n",
    "            cv2.putText(img, txt, (xyxy_i[0], xyxy_i[1]), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                        clr, 3)\n",
    "    return img\n",
    "\n",
    "\n",
    "from yolo.utils.general import xywh2xyxy\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.mask import encode, decode, area, toBbox\n",
    "\n",
    "import numpy as np\n",
    "import pylab\n",
    "\n",
    "\n",
    "def get_img_and_all_bb(imgi):\n",
    "    root = r\"E:\\ori_disks\\D\\fduStudy\\labZXD\\repos\\datasets\\OmnidirectionalStreetViewDataset\\equirectangular\\JPEGImages\"\n",
    "    annFile = r\"E:\\ori_disks\\D\\fduStudy\\labZXD\\repos\\datasets\\OmnidirectionalStreetViewDataset\\equirectangular\\all.json\"\n",
    "    coco = COCO(annFile)\n",
    "    imgIds = coco.getImgIds()\n",
    "    images = coco.loadImgs(imgIds)\n",
    "    image = images[imgi]['file_name']\n",
    "    image = os.path.join(root, image)\n",
    "\n",
    "    annIds = coco.getAnnIds(imgIds=imgIds[imgi])\n",
    "    ann = coco.loadAnns(\n",
    "        annIds)  # [{'area': 6000, 'iscrowd': 0, 'image_id': 3, 'bbox': [481, 533, 75, 80], 'category_id': 0, 'id': 17, 'ignore': 0, 'segmentation': []}, {'area': 7047,\n",
    "    image = cv2.imread(image)\n",
    "    boxes = np.array([a['bbox'] for a in ann])\n",
    "    scale = 2\n",
    "    image = cv2.resize(image, (image.shape[1] // scale, image.shape[0] // scale))\n",
    "    boxes = boxes // scale\n",
    "    return image, boxes\n",
    "\n",
    "\n",
    "\n",
    "im, bb = get_img_and_all_bb(17)\n",
    "poses = ['center']\n",
    "patch = 20\n",
    "im = cv2.resize(im, (600, 300))\n",
    "im = basketball_transition(im, patch_size=patch, poses=poses, ratio_v=(0, 1))\n",
    "for k in poses:\n",
    "    im2 = im[k].copy()\n",
    "im2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "openmmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
